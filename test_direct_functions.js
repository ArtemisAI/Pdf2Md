#!/usr/bin/env node

/**
 * Direct test of audio transcription functions
 */

import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

async function testDirectAudioFunctions() {
  console.log('ğŸµ Testing Direct Audio Functions');
  console.log('=================================\n');

  try {
    // Test file
    const audioPath = path.join(__dirname, 'tests', 'audio_samples', 'github_friendly', 'test_002_duration_21kb.mp3');
    console.log(`ğŸ“ Test file: ${audioPath}`);
    console.log(`ğŸ“ File size: ~21KB (short test file)`);

    // Import the audio functions directly
    const audio = await import('./dist/audio/index.js');
    console.log('âœ… Audio module loaded');

    // Test 1: Direct EnhancedAudioTranscription
    console.log('\nğŸ”„ Test 1: Direct EnhancedAudioTranscription');
    const startTime1 = Date.now();

    try {
      const transcriber = new audio.EnhancedAudioTranscription();
      const result1 = await transcriber.transcribe({
        filepath: audioPath,
        language: 'en'
      });

      const duration1 = Date.now() - startTime1;
      console.log(`âœ… Direct transcription completed in ${duration1}ms`);
      console.log(`ğŸ“ Result length: ${result1?.text?.length || 0} characters`);
      if (result1?.text) {
        console.log(`ğŸ“„ Content preview: ${result1.text.substring(0, 100)}...`);
      }
    } catch (error) {
      console.log('âŒ Direct transcription error:', error.message);
    }

    // Test 2: Queue-based transcription
    console.log('\nğŸ”„ Test 2: Queue-based transcription');
    const startTime2 = Date.now();

    try {
      const taskId = await audio.transcribeAudio({
        filepath: audioPath,
        language: 'en',
        config: {
          modelSize: 'tiny',
          device: 'auto'
        }
      });

      const duration2 = Date.now() - startTime2;
      console.log(`âœ… Queue transcription started in ${duration2}ms`);
      console.log(`ğŸ“ Task ID: ${taskId}`);

      // Wait a bit and check status
      await new Promise(resolve => setTimeout(resolve, 2000));

      const status = await audio.getTaskStatus(taskId);
      console.log(`ğŸ“Š Task status: ${status?.status}`);
      console.log(`ğŸ“ˆ Progress: ${status?.progress}%`);

      if (status?.status === 'completed') {
        const result = audio.getTranscriptionResult(taskId);
        if (result) {
          console.log(`ğŸ“„ Final result length: ${result.text?.length || 0} characters`);
          if (result.text) {
            console.log(`ğŸ“„ Content preview: ${result.text.substring(0, 100)}...`);
          }
        }
      }

    } catch (error) {
      console.log('âŒ Queue transcription error:', error.message);
    }

  } catch (error) {
    console.log('âŒ Test setup error:', error.message);
    console.log('Stack trace:', error.stack);
  }

  console.log('\nğŸ Direct Audio Functions Test Complete!');
}

testDirectAudioFunctions().catch(console.error);